{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f938262-3f91-4fbb-8321-4a413e1128b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4e3650-24f6-438b-9c27-2e31c423b396",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e102e72-9bf1-4335-99af-bee40337bde4",
   "metadata": {},
   "source": [
    "- linear regression fits a straight line through observed data, showing it is linear, and predicting values for new and unobserved data\n",
    "- machine learning practicioners often use train-test-splits to validate data\n",
    "- statisticians like to use prediction intervals and correlations\n",
    "- linear regression should not be used to make predictions outside the range of the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2985259c-6136-4512-8d60-103d90dc77b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.93939394]\n",
      "4.73333333333334\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create dataset of 10 dogs and n pet visits\n",
    "X = np.array([1,2,3,4,5,6,7,8,9,10]).reshape(-1, 1)\n",
    "Y = np.array([5,10,10,15,14,15,19,18,25,23])\n",
    "\n",
    "fit = LinearRegression().fit(X,Y)\n",
    "\n",
    "m = fit.coef_\n",
    "b = fit.intercept_\n",
    "print(m)\n",
    "print(b)\n",
    "\n",
    "plt.plot(X,Y,\"o\")\n",
    "plt.plot(X, m*X + b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb822f-67e2-4390-bbb6-7fee1e7978aa",
   "metadata": {},
   "source": [
    "**Residuals and Squared Errors**\n",
    "- 2 questions that are fundamental to model training:\n",
    "- what defines the \"best fit\"?\n",
    "- > minimize sum of squared residuals (or errors)\n",
    "  > residual: difference between predicted y value and actual y value\n",
    "- what gets the \"best fit\"?\n",
    "- > how do we find the best m and b value that create the line with the least sum of squares?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f73dc-12b3-446a-84fe-05c5095e2ff7",
   "metadata": {},
   "source": [
    "**Machine Learning Training basic concept**\n",
    "- we provide data and a loss function (or objective function)\n",
    "- having a loss function that calculates the error of a model\n",
    "- finding the parameters of the loss function that gives the lowest loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7494548-8f75-49e1-8bd4-751f71ca585a",
   "metadata": {},
   "source": [
    "**Finding the best fit line**\n",
    "- algorithms: closed form, matrix inversion, matrix decomposition, gradient descent, stochastic gradient descent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70098eb-584f-4493-a331-5beb4e9557da",
   "metadata": {},
   "source": [
    "**Closed Form Equation**\n",
    "- if there is only 1 input variable and few datapoints, we can use closed form equation\n",
    "- this fits a linear regression by exact calculation\n",
    "- m = (n*sum(xy) - sum(x) * sum(y)) / (n*sum(x**2) - sum(x)**2)\n",
    "- b = sum(y)/n - m * sum(x)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "971467ed-8d7d-40bc-b055-755f5bdf29eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9393939393939394 4.7333333333333325\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "y = [5,10,10,15,14,15,19,18,25,23]\n",
    "n = len(x)\n",
    "\n",
    "m = (n*sum(x[p-1]*y[p-1] for p in x) - sum(x[p-1] for p in x) *\n",
    "    sum(y[p-1] for p in x)) / (n*sum(x[p-1]**2 for p in x) -\n",
    "    sum(x[p-1] for p in x)**2)\n",
    "\n",
    "b = (sum(y[p-1] for p in x) / n) - m * sum(x[p-1] for p in x) / n\n",
    "\n",
    "print(m, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d84a3-007e-4431-979c-b91d0ace9fc7",
   "metadata": {},
   "source": [
    "**Inverse Matrix Techniques**\n",
    "- b = (Xt * X)**(-1) * (Xt * y)\n",
    "- b = vector of coefficients\n",
    "- X = matrix of input variable values\n",
    "- y = vector of output variable values\n",
    "- finds vector of coefficients given matrix of input variables and vector of output variables\n",
    "- not so good when amount of data and dimensions are high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a032cfd-62a9-416d-92df-db33f559be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.93939394 4.73333333]\n",
      "[ 6.67272727  8.61212121 10.55151515 12.49090909 14.43030303 16.36969697\n",
      " 18.30909091 20.24848485 22.18787879 24.12727273]\n"
     ]
    }
   ],
   "source": [
    "# input and output data\n",
    "# X: have to add column of ones so get the coefficient for the intercept\n",
    "X = np.array([[1,2,3,4,5,6,7,8,9,10], [1,1,1,1,1,1,1,1,1,1]]).T\n",
    "Y = np.array([5,10,10,15,14,15,19,18,25,23])\n",
    "\n",
    "# inverse matrix technique\n",
    "b = np.linalg.inv((X.T @ X)) @ (X.T @ Y)\n",
    "print(b)\n",
    "\n",
    "# use coefficients to predict outcomes based on input data\n",
    "y_pred = X @ b\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905c828-0f57-4355-b7bb-2899b33070ed",
   "metadata": {},
   "source": [
    "**Matrix Decomposition (QR decomposition)**\n",
    "- better than inverse matrix if alot of data\n",
    "- first decompose matrix: X = Q * R\n",
    "- then calculate coefficients: b = R**(-1) * Qt * y\n",
    "- QR decomposition is used for linear regression in many scientific libraries, because it scales well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f45250f-f3ec-4010-8ed2-40f042f9fbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.09647191e-02 -5.85540044e-01]\n",
      " [-1.01929438e-01 -4.87950036e-01]\n",
      " [-1.52894157e-01 -3.90360029e-01]\n",
      " [-2.03858877e-01 -2.92770022e-01]\n",
      " [-2.54823596e-01 -1.95180015e-01]\n",
      " [-3.05788315e-01 -9.75900073e-02]\n",
      " [-3.56753034e-01 -1.18221328e-17]\n",
      " [-4.07717753e-01  9.75900073e-02]\n",
      " [-4.58682472e-01  1.95180015e-01]\n",
      " [-5.09647191e-01  2.92770022e-01]]\n",
      "[[-19.62141687  -2.80305955]\n",
      " [  0.          -1.46385011]]\n",
      "[1.93939394 4.73333333]\n",
      "[ 6.67272727  8.61212121 10.55151515 12.49090909 14.43030303 16.36969697\n",
      " 18.30909091 20.24848485 22.18787879 24.12727273]\n"
     ]
    }
   ],
   "source": [
    "# input and output data\n",
    "# X: have to add column of ones so get the coefficient for the intercept\n",
    "X = np.array([[1,2,3,4,5,6,7,8,9,10], [1,1,1,1,1,1,1,1,1,1]]).T\n",
    "Y = np.array([5,10,10,15,14,15,19,18,25,23])\n",
    "\n",
    "# decompose using QR decomposition\n",
    "Q, R = np.linalg.qr(X)\n",
    "print(Q)\n",
    "print(R)\n",
    "\n",
    "# calculate coefficients\n",
    "b = np.linalg.inv(R) @ (Q.T @ Y)\n",
    "print(b)\n",
    "\n",
    "# predict new y based on X input values and b coefficients\n",
    "print(X @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b090f6b-2e08-4dae-ae23-4ba9f1ca2143",
   "metadata": {},
   "source": [
    "**Gradient Descent**\n",
    "- imagine your on a mountain landscape\n",
    "- the landscape are all possible sum of square losses\n",
    "- we cannot see the entire landscape, only whats right around us\n",
    "- and we want to get to the lowest point, where the sum of square loss is the lowest\n",
    "- so we iteratively take steps into the direction where the downward slope is big, hoping to find the lowest point\n",
    "- partial derivative lets us see the slope for every parameter (ie m and b)\n",
    "- we step in directions for m and b where the slope goes downward\n",
    "- as a step size we take a fraction of the slope\n",
    "- this fraction is the learning rate\n",
    "- low learning rate: algorithms takes long time but is more precise\n",
    "- high learning rate: algorithm is faster but is less precise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e0069-fccc-4dbf-9c50-6022c980b1d5",
   "metadata": {},
   "source": [
    "**Gradient Descent example**\n",
    "- using gradient descent to find minimum of parabola\n",
    "- start with a random x value\n",
    "- get the slope at x using derivative\n",
    "- substract a fraction of the slope from x\n",
    "- x will keep decreasing to the bottom of the curve\n",
    "- if it passes the zero point, x will rise again, but so will slope that is the substracted again\n",
    "- hypothetically, if x arrives exactly at zero point, slope is zero so nothing is substracted from x. x stays the same for remaining iterations\n",
    "- also, when x gets closer to zero, the slope gets smaller, so the substracted learning rate is smaller, making x reduce slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e0e55bb-deb5-45f9-9966-95b8ee169a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2  -  4.64\n",
      "2.3600000000000003  -  4.409599999999999\n",
      "2.4880000000000004  -  4.262143999999999\n",
      "2.5904000000000003  -  4.16777216\n",
      "2.67232  -  4.1073741824\n",
      "2.737856  -  4.068719476736\n",
      "2.7902848  -  4.04398046511104\n",
      "2.83222784  -  4.028147497671066\n",
      "2.8657822719999997  -  4.018014398509482\n",
      "2.8926258176  -  4.011529215046068\n",
      "2.91410065408  -  4.007378697629484\n",
      "2.931280523264  -  4.00472236648287\n",
      "2.9450244186112  -  4.003022314549036\n",
      "2.95601953488896  -  4.001934281311383\n",
      "2.964815627911168  -  4.001237940039285\n",
      "2.9718525023289346  -  4.000792281625142\n",
      "2.9774820018631476  -  4.000507060240091\n",
      "2.981985601490518  -  4.000324518553659\n",
      "2.9855884811924147  -  4.000207691874341\n",
      "2.9884707849539316  -  4.000132922799579\n"
     ]
    }
   ],
   "source": [
    "# function for which we find x value that produces the lowest point using gradient descent\n",
    "def f(x):\n",
    "    return (x-3)**2 + 4\n",
    "\n",
    "# partial derivative for x\n",
    "def dx_f(x):\n",
    "    return 2*(x-3)\n",
    "\n",
    "# learning rate\n",
    "L = 0.1\n",
    "\n",
    "# number of iterations\n",
    "n = 20\n",
    "\n",
    "# start at a random x value\n",
    "x = random.randint(-15,15)\n",
    "\n",
    "# gradient descent\n",
    "for i in range(n):\n",
    "\n",
    "    # calculate derivative value at x (slope)\n",
    "    dx = dx_f(x)\n",
    "\n",
    "    # update x by substracting the learning rate * slope\n",
    "    x -= L * dx\n",
    "    print(x, \" - \", f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb71a75-db15-4a8b-b788-d46d95ea7b9c",
   "metadata": {},
   "source": [
    "**Gradient Descent and Linear Regression**\n",
    "- in linear regression we already know the x and y values, because they are provided as training data\n",
    "- we need to find m and b to get the best fit line through the x and y values\n",
    "- slopes for m and b: Partial derivatives for each of these\n",
    "- we are minimizing the sum of squares\n",
    "- so we need to take the derivatives of sum of square with respect to m and b\n",
    "- sum of square: sum(((mx + b) - y)**2)\n",
    "- dm = sum(2x * ((mx + b) - y))\n",
    "- db = sum(2 * ((mx + b) - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ef2081-158d-4366-866b-217845d46d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m =  1.9393939393939548  & b =  4.733333333333227\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "y = [5,10,10,15,14,15,19,18,25,23]\n",
    "\n",
    "# set initial values for m and b\n",
    "m = 0.0\n",
    "b = 0.0\n",
    "\n",
    "# Learning rate\n",
    "L = 0.001\n",
    "\n",
    "# number of iterations\n",
    "n = 100000\n",
    "\n",
    "# prepare lists for 3dplot\n",
    "m_list = []\n",
    "b_list = []\n",
    "e_list = [] # errors\n",
    "\n",
    "# Perform gradient descent\n",
    "for i in range(n):\n",
    "\n",
    "    # calc squared error for plotting\n",
    "    e = sum((((m * x[p-1] + b) - y[p-1])**2 for p in x))\n",
    "    \n",
    "    # slope with respect to m\n",
    "    D_m = sum(2 * x[p-1] * ((m * x[p-1] + b) - y[p-1]) for p in x)\n",
    "\n",
    "    # slope with respect to b\n",
    "    D_b = sum(2 * ((m * x[p-1] + b) - y[p-1]) for p in x)\n",
    "\n",
    "    # update m and b\n",
    "    m -= L * D_m\n",
    "    b -= L * D_b\n",
    "\n",
    "    # add data to lists for plotting\n",
    "    m_list.append(m)\n",
    "    b_list.append(b)\n",
    "    e_list.append(e)\n",
    "\n",
    "print(\"m = \", m, \" & b = \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d69106-743e-49e3-bbee-c84c60a75568",
   "metadata": {},
   "source": [
    "**Overfitting and Variance**\n",
    "- if we fit the model too well to the training data, it will be less good at predicting for new data (overfitting)\n",
    "- overfit model will have high variance in predicting for new data\n",
    "- thats why we use bias in a model: prioritizing a method (keeping a straight line) over fitting exactly to the training data\n",
    "- adding bias to a model counteracts overfitting with underfitting\n",
    "- Ridge Regression: Adds further bias to regression through adding a penalty\n",
    "- Lasso regression removes noisy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b05f10-6d5d-4cdc-b86d-eb026b7f6c10",
   "metadata": {},
   "source": [
    "**Stochastic gradient descent**\n",
    "- it is unlikely that one would do regular gradient descent (batch gradient descent) where one trains on all available data\n",
    "- better: stochastic gradient descent (mini batch gradient descent) where in each iteration you only train on a sample of the data\n",
    "- makes computation more efficient, as each iteration on ly trains non a sample of the data\n",
    "- reduces overfitting: Each iteration there will be a different loss landscape (based on the sample the iteration trains on) which means the algorithm will not settle in the global minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55eb5a4c-be8f-432a-97a5-b81eae89cf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0285 0.004\n",
      "10000 2.3535760103759302 1.875233542862461\n",
      "20000 2.2064820626847936 2.8490987360865336\n",
      "30000 2.1187637896104516 3.492794671003066\n",
      "40000 2.0575517119959623 3.913604893634368\n",
      "50000 2.0131102495570685 4.196016370047888\n",
      "60000 1.9738021046896421 4.3834487393903965\n",
      "70000 1.9671248460073738 4.4997500720209285\n",
      "80000 1.9335007811216114 4.58632752429507\n",
      "90000 1.9627904251022696 4.65312862635246\n",
      "y = 1.9285259824870946x + 4.6858119643902025\n"
     ]
    }
   ],
   "source": [
    "# creating dataset\n",
    "data = {\"x\":[1,2,3,4,5,6,7,8,9,10],\n",
    "        \"y\":[5,10,10,15,14,15,19,18,25,23]}\n",
    "df = pd.DataFrame(data)\n",
    "X = df.iloc[:, 0].values\n",
    "Y = df.iloc[:, 1].values\n",
    "\n",
    "n = df.shape[0]  # rows\n",
    "\n",
    "# Building the model\n",
    "m = 0.0\n",
    "b = 0.0\n",
    "\n",
    "sample_size = 2  # sample size\n",
    "L = .0001  # The learning Rate\n",
    "epochs = 100000  # The number of iterations to perform gradient descent\n",
    "\n",
    "# Performing Stochastic Gradient Descent\n",
    "for i in range(epochs):\n",
    "    idx = np.random.choice(n, sample_size, replace=False)\n",
    "    x_sample = X[idx]\n",
    "    y_sample = Y[idx]\n",
    "\n",
    "    # The current predicted value of Y\n",
    "    Y_pred = m * x_sample + b\n",
    "\n",
    "    # d/dm derivative of loss function\n",
    "    D_m = (-2 / sample_size) * sum(x_sample * (y_sample - Y_pred))\n",
    "\n",
    "    # d/db derivative of loss function\n",
    "    D_b = (-2 / sample_size) * sum(y_sample - Y_pred)\n",
    "    m = m - L * D_m  # Update m\n",
    "    b = b - L * D_b  # Update b\n",
    "\n",
    "    # print progress\n",
    "    if i % 10000 == 0:\n",
    "        print(i, m, b)\n",
    "\n",
    "print(\"y = {0}x + {1}\".format(m, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afee60-e52a-4177-b4bc-98407b67fa82",
   "metadata": {},
   "source": [
    "**Correlation Coefficient**\n",
    "- same as pearson correlation\n",
    "- between -1 and 1\n",
    "- useful to see if there is possible relationship between two variables\n",
    "- less correlation, less useful for linear regression\n",
    "- correlation matrix: shows correlation between every pair of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77203243-f03c-4d87-8958-437cd9b4d1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x         y\n",
      "x  1.000000  0.957586\n",
      "y  0.957586  1.000000\n"
     ]
    }
   ],
   "source": [
    "# creating dataset\n",
    "data = {\"x\":[1,2,3,4,5,6,7,8,9,10],\n",
    "        \"y\":[5,10,10,15,14,15,19,18,25,23]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# calculate and print correlations\n",
    "correlations = df.corr(method=\"pearson\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd984d6c-6b5f-4a74-9870-9c62a6a92cbb",
   "metadata": {},
   "source": [
    "**Statistical significance**\n",
    "- consider: is correlation coincidental? or causal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536d54e-6226-4d32-9746-56d8c51960f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
