{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b62ca3-4a1d-4c6d-b822-b57340101244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, t, tstd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f126e-5952-4af5-bfe9-f33695e4e3e7",
   "metadata": {},
   "source": [
    "**Statistics Types**\n",
    "- descriptive statistics: used to describe and summarize data\n",
    "- inferential statistics: tries to uncover attributes of a larger population, usually based on a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c8ccb9-18f1-467b-a30f-ae19c04617f2",
   "metadata": {},
   "source": [
    "**Population**\n",
    "- particular group of interest that should be studied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e51fe-5f89-44b8-a1e2-b178db5b261d",
   "metadata": {},
   "source": [
    "**Sample**\n",
    "- subset of population that is ideally random an unbiased\n",
    "- is used to infer attributes about the population\n",
    "- population is usually to big, so samples are used\n",
    "- hard to get the bias out of the data though\n",
    "- ie how do i get a random sample of all universities in US to represent all students? Without injecting any selection bias?\n",
    "- *confirmation bias*: Selecting only data that supports your belief\n",
    "- *self-selection bias*: Selecting samples that are already pre-selected\n",
    "- *Survival bias*: Selects only the survivors, while the lost ones are not included in the sample\n",
    "- Computers don't recognize bias in data, that has to be done by the practicioner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6a8cb-cb0b-4c28-933d-aa3d9f92bc9e",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c04a2f-19c9-495d-9aed-501ff7398bf3",
   "metadata": {},
   "source": [
    "**Mean**\n",
    "- average\n",
    "- sample mean: x-bar\n",
    "- population mean: mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d67bef-c7f5-46b5-9869-72640684782e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.25"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [0,1,3,4,2,7,8,9]\n",
    "\n",
    "mean = sum(sample) / len(sample)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d5eb8-caca-4530-bbe2-fb2d9df8f3bf",
   "metadata": {},
   "source": [
    "**Weighted Mean**\n",
    "- weight each data point before summing\n",
    "- then divide by sum of weights, not the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2116f62-998e-45ae-99fa-fd0ffb1c0caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.63333333333333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [9,23,65,23,78]\n",
    "weights = [3,7,45,3,2]\n",
    "\n",
    "weighted_mean = sum(s * w for s,w in zip(sample, weights)) / sum(weights)\n",
    "weighted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5764b-e56a-4250-90c3-03627693ae5e",
   "metadata": {},
   "source": [
    "**Median**\n",
    "- middle most value in a set of ordered values\n",
    "- if n is even, you average the two center most values\n",
    "- median is helpful alternative to mean if the data is skewed by outliers\n",
    "- when median is very different from mean, you have skewed dataset with many outliers\n",
    "- mean is the 50% quantile (from 25%, 50%, 75%)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e76d3-7428-4470-a6a4-0f71b2f8feec",
   "metadata": {},
   "source": [
    "**Mode**\n",
    "- most frequent set of values in data set\n",
    "- useful in repetitive data and you want to know which value is most frequent\n",
    "- otherwise not used often\n",
    "- bimodal: 2 values with highest frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f485cb8-422e-46c1-924f-a243b4de38ef",
   "metadata": {},
   "source": [
    "**Variance**\n",
    "- measure for how spread out the data is\n",
    "- squared sum of differences between value and mean for each data point\n",
    "- then take the average\n",
    "- intuition: Average distance of a datapoint to the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef76199-c242-4f6b-aa05-264c451dc25e",
   "metadata": {},
   "source": [
    "**Standard Deviation**\n",
    "- square root of Variance. gets it closer to original scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda07715-9dd0-42ac-aa3b-8beb26cd005d",
   "metadata": {},
   "source": [
    "**Standard Deviation and Variance in Samples**\n",
    "- in samples, when dividing by the sample size, we divide by sample size - 1\n",
    "- we do this to decrease the bias\n",
    "- this increases the estimate of how spread out the data of the population is\n",
    "- since it is in any case most likely more spread out than the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d47e9-703b-4f04-9bbe-901412d58c5d",
   "metadata": {},
   "source": [
    "**The Normal Distribution**\n",
    "- most important distribution\n",
    "- most mass around its mean\n",
    "- is seen a lot in nature and sciences\n",
    "- *I think in all datasets where we can use normal distribution, this gives us a set of methods to infer certain characteristics about the dataset*\n",
    "- *properties*:\n",
    "- symmetrical: Both sides are identically mirrored at the mean\n",
    "- most mass is at center around mean\n",
    "- is has a spread (being narrow or wide) that is specified by standard deviation\n",
    "- tails are the least likely outcomes and approach, but never touch, zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d826ecd0-372b-4298-afe6-8465332e995d",
   "metadata": {},
   "source": [
    "**The probability Density Function (PDF)**\n",
    "- is the function that creates the normal distribution\n",
    "- can be used to look up likelyhoods at given values\n",
    "- its continuous, so we need to integrate it to get an area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e8d95-5f50-484d-ada9-d1c058d3acf6",
   "metadata": {},
   "source": [
    "**The cumulative distribution function**\n",
    "- finds the area under PDF (normal distribution)\n",
    "- like with beta distribution\n",
    "- ie whats the probability of a value being below x?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4893bde-7ed2-455d-9845-abbf8d9f10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5755943933826899\n"
     ]
    }
   ],
   "source": [
    "mean = 64.43\n",
    "std_dev = 2.99\n",
    "x = 65\n",
    "\n",
    "P = norm.cdf(x, mean, std_dev)\n",
    "\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079ba6da-7ad5-4a8e-8a48-c06065ac4d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4086326197841312"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of value being in certain area y - x\n",
    "\n",
    "mean = 70\n",
    "std_dev = 6.34\n",
    "x = 65\n",
    "y = 72\n",
    "\n",
    "P = norm.cdf(y, mean, std_dev) - norm.cdf(x, mean, std_dev)\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4132503b-c42d-4062-849d-e3515cb64bd9",
   "metadata": {},
   "source": [
    "**Inverse CDF**\n",
    "- opposite of CDF\n",
    "- under what value do x% of data points fall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad0d2dc-2906-4e7e-b4ff-fd0e61b89b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.3481123445849"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# under what value do 95% of data points fall?\n",
    "# loc = mean, scale = std_dev\n",
    "\n",
    "x = norm.ppf(.95, loc = 64.43, scale = 2.99)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017ff8c-1ceb-422b-af45-178bd48e645c",
   "metadata": {},
   "source": [
    "**Z scores**\n",
    "- standard normal distribution: mean = 0, std_dev = 1)\n",
    "- normal distributions are often scaled to standard normal distributions to make them more comparable\n",
    "- standard normal distribution expresses all x values in terms of std_dev.\n",
    "- Amount of std_devs is called the Z-Score\n",
    "- Z = (x - mean)/std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923e197-3ae5-4272-9f1d-c200e2c97522",
   "metadata": {},
   "source": [
    "**Coefficient of variation**\n",
    "- metric to discribe the spread of a distribution\n",
    "- cv = std_dev/mean\n",
    "- basically adjusts the std_dev for the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2204fd4-d934-47d8-815d-4e856708d04b",
   "metadata": {},
   "source": [
    "## Inferential Statistics\n",
    "- Infer stuff about population by using sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d87e3-9951-4d66-9b2a-2e210dec5590",
   "metadata": {},
   "source": [
    "**Central Limit Theorem**\n",
    "- uniform distribution: any value is equally likely, distribution becomes flat\n",
    "- but when these values are grouped and averaged, they become a normal distribution\n",
    "- *central limit theorem*: Interesting things happen when we take large enough samples of populations, calculate the mean of each sample, and plot as distribution:\n",
    "1. the mean of the sample means becomes the population mean\n",
    "2. if the population is normal, then the sample means will be normal\n",
    "3. if population is not normal, but sample size is greater 30, the sample means are still roughly normal distribution\n",
    "4. sample std_dev = population std_dev/sqrt(population size)\n",
    "- you need at least 31 samples to satisfy central limit theorem and see normal distribution\n",
    "- *then you can infer useful things about population using normal distribution, even if population is not normal*\n",
    "- less than 31 samples, you need to use T-distribution\n",
    "\n",
    "**probability distribution and sample size**\n",
    "- if population is very asymmetric, ie skewed, you need a lot bigger sample size to get the sample means looking like normal distribution\n",
    "- unimodal data: One peak. is good for central limit theorem\n",
    "- multimodal data: more peaks. need bigger sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266aae37-30ef-4e7a-9fc8-dd3ff8030bb9",
   "metadata": {},
   "source": [
    "**Confidence Intervals**\n",
    "\n",
    "-if we can get a sample of at least 31 data points, we can apply central limit theorem to calculate confidence interval, in which we have a certain confidence that a certain value will fall\n",
    "- Confidence Interval: Is the range in which a value falls\n",
    "- LOC (Level of confidence): The probability that a value falls in confidence interval\n",
    "- gives a confidence (ie 95% confidence (LOC)) that a specific value of the population (ie population mean) lies in a confidence Interval (ie 10 and 12) of the corresponding value of the sample\n",
    "- first choose a LOC (level of confidence) ie 95%\n",
    "- this is the desired confidence a value (ie population mean) should have\n",
    "- we can use central limit theorem to infer what this range for the population mean is\n",
    "\n",
    "*Calculating Confidence Interval*\n",
    "- First I need *critical z value*\n",
    "- critical z value leaves 95% probability in the center, meaning remaining 5% is split up in 2.5% on either side\n",
    "- *How is this symmetrical range containing 95% calculated?*\n",
    "- we can use inverse CDF to get the x values for .025 and .975, the space between represents the symmetrical 95% area around the center\n",
    "- then we use those x values and calculate the corresponding z values, that are the upper and lower bounds for the 95% center area\n",
    "- since we use standard normal distribution that is centered around mean 0, the upper and lower z values will be the same but other sign. so +z and - z\n",
    "- then calculate *margin of error*, which is the range around the sample mean that contains the population mean that level of confidence (95% certainty)\n",
    "- margin of error around the confidence interval = confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a47c6a-7428-43cf-bc6e-9d793b7c9c19",
   "metadata": {},
   "source": [
    "**Confidence Intervals my explanation**\n",
    "\n",
    "-You need: LOC, standard deviation, sample size\n",
    "- Confidence Interval: Interval in which I expect a value of the population to lie, based on the corresponding value of the sample\n",
    "- LOC: Level of confidence I want to have that the population value falls in Confidence Interval. Often 95%\n",
    "- to calculate the confidence interval, I have to calculate its upper and lower value, which hold 95% probability that the population value falls into this interval\n",
    "- We use inverse CDF to calculate two x values: X1 below which the bottom 2,5% of probabillity lies and X2 above which the top 2,5% of probability lie\n",
    "- this means the middle hold the 95% probability\n",
    "- Using those x values we calculate the corresponding z values (remember: standard normal distribuiton)\n",
    "- we can than use margin of erro formula to calculat a +- value\n",
    "- we can use this on the sample value to calculate the range (confidence interval) where population value is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106ff90b-ecf5-4f6a-b190-53507cb3209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63.68635915701992, 65.12964084298008)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def critical_z_value(p):\n",
    "    norm_dist = norm(loc=0.0, scale=1.0)\n",
    "    left_tail_area = (1.0 - p) / 2.0\n",
    "    upper_area = 1.0 - ((1.0 - p) / 2.0)\n",
    "    return norm_dist.ppf(left_tail_area), norm_dist.ppf(upper_area)\n",
    "\n",
    "\n",
    "def confidence_interval(p, sample_mean, sample_std, n):\n",
    "    # Sample size must be greater than 30\n",
    "\n",
    "    lower, upper = critical_z_value(p)\n",
    "    lower_ci = lower * (sample_std / sqrt(n))\n",
    "    upper_ci = upper * (sample_std / sqrt(n))\n",
    "\n",
    "    return sample_mean + lower_ci, sample_mean + upper_ci\n",
    "\n",
    "print(confidence_interval(p=.95, sample_mean=64.408, sample_std=2.05, n=31))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678b4c0-cf70-412b-9f5f-1c5c7b097965",
   "metadata": {},
   "source": [
    "**Confidence Intervals another explanation**\n",
    "- confidence interval: the area in which a value lies with certain confidence\n",
    "- LOC or alpha: The confidence (probability) with which a value lies in confidence interval\n",
    "- critical_z_value: range in a standard normal distribution, that gives LOC (alpha) probability around the center\n",
    "- Margin of error: Range around the sample mean that contains population mean at LOC confidence\n",
    "- Margin of error formular: +-Zc * (std_dev/sqrt(n))\n",
    "- Process: First calculate critical Z value, then calculate margin of error. Then apply margin of error on sample mean to calculate confidence interval\n",
    "- to get critical z: determine probability that should be on left and right tail. If LOC = 95%, then 2.5% needs to be on left and right tail. So the 95% are centered in the middle\n",
    "- then use inverse CDF to get the x values (or in this case z alues), that determine the upper and lower bound of LOC area\n",
    "-  Then use critical z value to calculate error of margin\n",
    "-  then use error of margin to calculate confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ab31b4-e12c-41b2-a2bf-b71e0df20653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.678359157019926 65.12164084298009\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# create standard normal distribution\n",
    "std_norm = norm(loc = 0.0, scale = 1.0)\n",
    "\n",
    "# set LOC to 95%, std_dev = 2.05, n = 31, mean = 64.408\n",
    "p = .95\n",
    "std_dev = 2.05\n",
    "n = 31\n",
    "mean = 64.40\n",
    "\n",
    "# calculate probabilities for which we need to get the z values\n",
    "# example: LOC = 95%\n",
    "left_tail_prob = (1.0-p)/2.0 # 0.025\n",
    "right_tail_prob = 1 - left_tail_prob # 0.975\n",
    "\n",
    "# calculate z values\n",
    "z_lower = std_norm.ppf(left_tail_prob) # -1.959...\n",
    "z_upper = std_norm.ppf(right_tail_prob) # 1.959...\n",
    "\n",
    "# margin of error. calculate lower margin and upper margin of confidence interval (ci)\n",
    "error_margin_lower = z_lower * (std_dev / sqrt(n)) # -0.721....\n",
    "error_margin_upper = z_upper * (std_dev / sqrt(n)) # 0.721....\n",
    "\n",
    "# calculate confidence interval\n",
    "ci_lower = mean + error_margin_lower # 63.678....\n",
    "ci_upper = mean + error_margin_upper # 65.121....\n",
    "\n",
    "print(ci_lower, ci_upper)\n",
    "\n",
    "# interpretation:\n",
    "# I am 95% confident that the population mean will be between 63.678 and 65.121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec317a-6f1c-42bc-9f1b-1396b2e6ab57",
   "metadata": {},
   "source": [
    "**P values**\n",
    "- p value = probability that an experiment result occured by chance and not by the assumed explanation\n",
    "- Null Hypothesis (H0): Variable in question had no impact on the result and any positive result is random luck\n",
    "- Alternative Hypothesis (H1): The variable in question (control variable) is causing the positive result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67648822-e8d5-466c-b5fe-966984b1a401",
   "metadata": {},
   "source": [
    "**One Tailed Test**\n",
    "- H0: x >= certain value\n",
    "- H1: x < certain value\n",
    "- One Tailed because hypotheses is only tested on one side of a value (in this case < certain value)\n",
    "- significance level (alpha): if p value higher than this, reject sample\n",
    "- to calculate alpha use inverse cdf as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4396e440-ce56-46d8-99b1-2185f12486cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.53271955957279\n"
     ]
    }
   ],
   "source": [
    "# cold has 18 days mean recovery, 1.5 std_dev\n",
    "mean = 18\n",
    "std_dev = 1.5\n",
    "\n",
    "# what x value has 5% of probability under it?\n",
    "# using inverse cdf\n",
    "x = norm.ppf(0.05, mean, std_dev)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430867d-8540-4389-a47e-0b6dccd7b53c",
   "metadata": {},
   "source": [
    "- example above means:\n",
    "- if another sample has a mean of below 15.53, then the likelyhood that it is due to chance is below 5%\n",
    "- so if a cold treatment yields a mean recovery time of below 15.53, the likelyhood of this being due to chance and not the medicine is below 5%\n",
    "- so the medicine is statistically working\n",
    "- below: calculate p-value of sample that yielded mean of 16 to see if it is higher than alpha calculated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78785e37-cef4-4f4a-864d-110e4e33e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09121121972586788\n"
     ]
    }
   ],
   "source": [
    "# example where a drug yields a mean of 16\n",
    "# calculating p value: how likely is this result due to chance?\n",
    "\n",
    "# cold has 18 days mean recovery, 1.5 std_dev\n",
    "mean = 18\n",
    "std_dev = 1.5\n",
    "\n",
    "# p value of experiment that yields mean of 16\n",
    "p_value = norm.cdf(16, mean, std_dev)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678e9b5-baf7-4238-9389-82e1c1772b22",
   "metadata": {},
   "source": [
    "**Two tailed test**\n",
    "- looks on both sides of a value\n",
    "- using equal and not equal\n",
    "- H0: mean = 18\n",
    "- H1: mean != 18\n",
    "- now we are testing for statistical significance on each side\n",
    "- so if we set alpha to 5%, we split it to 2.5% on either side\n",
    "- if experiment mean is outside those areas, we reject H0\n",
    "- example below: if sample mean lands within those bounds, it is not statistically significant, because likelyhood of it being due to chance is hihgher than 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a647f2e7-393e-4822-9c3a-64daa76d0179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.060054023189918\n",
      "20.93994597681008\n"
     ]
    }
   ],
   "source": [
    "# calculating range for a 2 sided statistical significance of 5% (2.5% on each side)\n",
    "\n",
    "# cold has 18 days mean recovery and 1.5 std_dev\n",
    "mean = 18\n",
    "std_dev = 1.5\n",
    "\n",
    "# which x value has 2.5% of probability below it?\n",
    "x1 = norm.ppf(0.025, mean, std_dev)\n",
    "\n",
    "# which area has 97.5% of probability below it (so 2.5% probability above it)?\n",
    "x2 = norm.ppf(0.975, mean, std_dev)\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c723ed-6fba-4f31-b5f1-2989205d836b",
   "metadata": {},
   "source": [
    "- if calculating p-value for 2 tailed test, add the p-values for each side\n",
    "- example: population_mean = 18, sample_mean = 16\n",
    "- calculate p for below 16 and above 20\n",
    "- because we also take p for symmetrical other side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3f92a5-97e1-4d4d-b96d-2bf2c70882d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18242243945173575\n"
     ]
    }
   ],
   "source": [
    "# cold has 18 days mean recovery, and std_dev 1.5\n",
    "mean = 18\n",
    "std_dev = 1.5\n",
    "\n",
    "# probability of 16 days or less\n",
    "p1 = norm.cdf(16, mean, std_dev)\n",
    "\n",
    "# probability of 20 days or more\n",
    "p2 = 1.0 - norm.cdf(20, mean, std_dev)\n",
    "\n",
    "# total probability of x being outside of significance threshold (alpha)\n",
    "p = p2 + p1\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b9607-1d2a-4b4d-abd0-c5010a7d3d7e",
   "metadata": {},
   "source": [
    "- above example means the outcome has a likelyhood of 18% to be down to chance\n",
    "- so it is statistically insignificant\n",
    "- two tailed tests are usually preferable\n",
    "- they make it more difficult to reject H0\n",
    "- and are not biased to only testing one side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbb650-234f-4e1b-b891-6e0471843137",
   "metadata": {},
   "source": [
    "**P values in hypothesis testing my own explanation**\n",
    "- P value: probability of an event occuring outside of a x value\n",
    "- example: mean 10, sample mean 12\n",
    "- one tailed test: p value = probability of sample mean being greater 12. If higher than alpha: insgnificant, prob just due to chance\n",
    "- two tailed test: p value = probability of sample mean being greater than 12 or less than 8. rest same. Can calculate p1 and double it due to symmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a428b28-c4ea-473a-9516-803d58daf7f2",
   "metadata": {},
   "source": [
    "**T-Distribution**\n",
    "- when dealing with 30 samples or less\n",
    "- T-distrbution is like normal distribution but with fatter tails\n",
    "- so more probability in the tails compared to normal distribution\n",
    "- reflects more variance and uncertainty\n",
    "- after approaching 31 items in sample, T-distribution reflects normal distribution\n",
    "- for confidence intervals you calculate critical t value, analog to critical z value for normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994f59dc-6ffc-473d-afcc-f53f0a68b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.063898561628021 2.063898561628021\n"
     ]
    }
   ],
   "source": [
    "# get critical value range for 95% confidence interval\n",
    "# with sample size = 25\n",
    "# means: I am 95% confident the population mean falls within this value range of sample mean (if mean is taken as metric)\n",
    "\n",
    "n = 25\n",
    "lower = t.ppf(.025, df = n-1)\n",
    "upper = t.ppf(.975, df = n-1)\n",
    "\n",
    "print(lower,upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf90514-33fd-450f-91ca-df6d3c235fc7",
   "metadata": {},
   "source": [
    "- df = degrees of freedom and should be sample size - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003f0dd-7377-4a14-8154-36df4e5ad33a",
   "metadata": {},
   "source": [
    "**Beyond the Mean**\n",
    "- in the example abpve we used confidence intervals and hypothesis testing with the mean\n",
    "- we can also use other values like variance and std_dev and proportions, but then we need other distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223f48d-ec48-4866-a5bb-4c5fa574a0db",
   "metadata": {},
   "source": [
    "**Big Data Considerations**\n",
    "- law of truly large numbers: Rare events are likely to be found, we just dont know which ones\n",
    "- so we cant really draw conclusions of finding a rare event at random\n",
    "- can we find it again with new data? Did we speculate it exists and then find it? Is there a good reasonable explanation for it?\n",
    "- if no: the rare event probably is completely random and no info should be infered from it\n",
    "- to not fall for this trap: Use structured hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73945c60-3727-4d05-bdb6-854f0a8cb123",
   "metadata": {},
   "source": [
    "**Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ac0f4-74f1-4b9c-933b-a016b9651ac6",
   "metadata": {},
   "source": [
    "**1)**\n",
    "- diameter soll: 1.75 mm\n",
    "- diameter samples: 1.78, 1.75, 1.72, 1.74, 1.77\n",
    "- calculate mean and std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec9d60e3-4d53-4c6a-970e-e2e2c3780adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.752 0.023874672772626667\n"
     ]
    }
   ],
   "source": [
    "list = [1.78, 1.75, 1.72, 1.74, 1.77]\n",
    "\n",
    "# mean = sum / n\n",
    "mean = sum(list)/len(list)\n",
    "\n",
    "# std_dev = sqrt(sum of differences to mean) squared\n",
    "std_dev = tstd(list)\n",
    "\n",
    "print(mean, std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b9c31-a42d-43de-92c4-917d0e285907",
   "metadata": {},
   "source": [
    "**2)**\n",
    "- mean consumer life: 42 months\n",
    "- std_dev 8 months\n",
    "- normal distribution\n",
    "- probability a random iphon will last between 20 and 30 months?\n",
    "- my approach: cdf, find probability for the x values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ddfc93-dc2b-4a7c-9d3b-f035d06f8401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06382743803380352\n"
     ]
    }
   ],
   "source": [
    "mean = 42\n",
    "std_dev = 8\n",
    "\n",
    "# P life between 20 and 30 months\n",
    "p = norm.cdf(30, mean, std_dev) - norm.cdf(20, mean, std_dev)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319e564-3842-457f-8af6-584bca8c15fd",
   "metadata": {},
   "source": [
    "**3)**\n",
    "- pop_mean = 1.75 (to be confirmed)\n",
    "- n_sample = 34\n",
    "- sample_mean = 1.715588\n",
    "- sample_std_dev = 0.029252.\n",
    "- what is 99% confidence interval of population mean?\n",
    "- solution process: for p = .99 get critical z values, then margin of error, then confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae7e14a5-2c5f-458a-a68b-6b358cb2945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7026658973748656 1.7285101026251342\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# create standard normal distribution\n",
    "std_norm = norm(loc = 0.0, scale = 1.0)\n",
    "\n",
    "# set variables\n",
    "p = .99\n",
    "std_dev = 0.029252\n",
    "n = 34\n",
    "mean = 1.715588\n",
    "\n",
    "# calculate probabilities for which we need to get the z values\n",
    "# example: LOC = 99%\n",
    "left_tail_prob = (1.0-p)/2.0\n",
    "right_tail_prob = 1 - left_tail_prob\n",
    "\n",
    "# calculate z values\n",
    "z_lower = std_norm.ppf(left_tail_prob)\n",
    "z_upper = std_norm.ppf(right_tail_prob)\n",
    "\n",
    "# margin of error. calculate lower margin and upper margin of confidence interval (ci)\n",
    "error_margin_lower = z_lower * (std_dev / sqrt(n))\n",
    "error_margin_upper = z_upper * (std_dev / sqrt(n))\n",
    "\n",
    "# calculate confidence interval\n",
    "ci_lower = mean + error_margin_lower\n",
    "ci_upper = mean + error_margin_upper\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e269541e-a19d-422b-9100-47e87e8d32e6",
   "metadata": {},
   "source": [
    "**4)**\n",
    "- mean pop = 10345\n",
    "- std_dev pop = 552\n",
    "- n sample = 45\n",
    "- mean sample = 11641\n",
    "- did sample campaign effect sales?\n",
    "\n",
    "- my approach\n",
    "- is sample mean due to randomness? Or due to campaign effect?\n",
    "- I want to be 95% sure it is due to campaign effect\n",
    "- H0: mean_sample_real = 10345\n",
    "- H1: mean_sample_real != 10345\n",
    "- alpha = .05 (1 - LOC)\n",
    "- can use either p value or hypothesis testing for this. Here I will use p value\n",
    "- p value process: calculate the probability that the real pop mean lies out side of sample mean. Two tailed test: on both sides. This probability is the p value. compare it to alpha. if its higher, its statistically insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1009bd3c-0d9f-4ab4-99ae-0c6aaf54e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018883335964961383\n"
     ]
    }
   ],
   "source": [
    "mean = 10345\n",
    "std_dev = 552\n",
    "sample_mean = 11641\n",
    "sample_mean_mirror = mean - (sample_mean - mean)\n",
    "\n",
    "# probability of 11641 dollars or more\n",
    "p1 = 1 - norm.cdf(sample_mean, mean, std_dev)\n",
    "\n",
    "# probability of 996 or less\n",
    "p2 = norm.cdf(sample_mean_mirror, mean, std_dev)\n",
    "\n",
    "print(p1 + p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43758a72-43aa-4172-8346-708ac7a8f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concerning example above\n",
    "# due to simmetry, I could have simply doubled p1 instead of calculating p2 (p1 and p2 are the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3a08e-dbfa-4e45-ba4f-066350075520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
